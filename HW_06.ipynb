{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Homework 6**\n",
    "\n",
    "Due: **November 5th, 5pm** (late submission until November 8th, 5pm -- no submission possible afterwards)\n",
    "\n",
    "Written assignment: 15 points\n",
    "\n",
    "Coding assignment: 20 points\n",
    "\n",
    "Project report: 10 points\n",
    "\n",
    "### Name: [Yawen Tan]\n",
    "\n",
    "### Link to the github repo: [https://github.com/IsabellaTan/Brown-DATA2060-HW6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Written Assignment** (15 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Problem 1: VC Dimension**\n",
    "\n",
    "For any hypothesis space $\\mathcal{H}$ on domain $\\mathcal{X}$, to show\n",
    "that the VC Dimension of $\\mathcal{H}$ is $d$, you should prove each of\n",
    "the following:\n",
    "\n",
    "-   There exists a set $C \\subset \\mathcal{X}$ of size $d$ such that\n",
    "    $\\mathcal{H}$ shatters $C$\n",
    "\n",
    "-   There does not exist a set $C' \\subset \\mathcal{X}$ of size $d + 1$\n",
    "    such that $\\mathcal{H}$ shatters $C'$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Part 1**\n",
    "\n",
    "Compute and prove the VC dimension for the following hypothesis spaces:\n",
    "\n",
    "a.  The class of signed intervals in $\\mathbb{R}$, $\\mathcal{H} = \\{h_{a,b,s} : a \\leq b, s \\in \\{-1, 1\\}\\}$ where: <br> \n",
    "$$h_{a,b,s} = \\begin{cases} s & \\text{if} \\; x \\in [a, b] \\\\ -s & \\text{if} \\; x \\not \\in [a,b] \\end{cases}$$\n",
    "\n",
    "b.  The class of origin-centered spheres in $\\mathbb{R}^d$,\n",
    "    $\\mathcal{H}\n",
    "        = \\{h_{a,s} : s \\in \\{-1, 1\\}, a \\in \\mathbb{R}\\}$ where:\n",
    "    $$h_{a,s} = \n",
    "            \\begin{cases}\n",
    "                s & \\text{if} \\; x \\; \\text{is within or on the origin centered sphere of radius} \\; a \\\\\n",
    "                -s & \\text{if} \\; x \\; \\text{is outside the origin centered sphere of radius} \\; a\n",
    "            \\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solutions:**\n",
    "\n",
    "**a.**\n",
    "\n",
    "VC dimension = 3\n",
    "\n",
    "We firstly prove that there exists a set $C \\subset \\mathcal{X}$ of size $3$ such that $\\mathcal{h}$ shatters $C$\n",
    "\n",
    "Let $x_1$ < $x_2$ < $x_3$, m=($x_1$ + $x_2$) / 2, n= m=($x_2$ + $x_3$) / 2 \n",
    "\n",
    "We will show that for every possible labeling of the three points $x_1$,$x_2$,$x_3$ (2^3=8 total), we can find an interval [a,b] and a sign s∈{−1,1} such that the classifier matches that labeling.\n",
    "\n",
    "- [1, 1, 1]: let s=1, [a,b] = [$x_1$, $x_3$] \n",
    "- [-1, 1, 1]: let s=1, [a,b] = [$x_2$, $x_3$]\n",
    "- [1, -1, 1]: let s=-1, [a,b] = [m, n]\n",
    "- [1, 1, -1]: let let s=1, [a,b] = [$x_1$, $x_2$]\n",
    "- [-1, -1, 1]: let s=-1, [a,b] = [$x_1$, $x_2$]\n",
    "- [-1, 1, -1]: let s=1, [a,b] = [m, n]\n",
    "- [1, -1, -1]: let s=-1, [a,b] = [$x_2$, $x_3$]\n",
    "- [-1, -1, -1]: let s=-1, [a,b] = [$x_1$, $x_3$]\n",
    "\n",
    "\n",
    "Then we prove that there does not exist a set $C' \\subset \\mathcal{X}$ of size $4$ such that $\\mathcal{h}$ shatters $C'$\n",
    "\n",
    "Let $x_1$ < $x_2$ < $x_3$ < $x_4$\n",
    "\n",
    "Consider the labeling pattern (1,−1,1,−1) which is in the set of size 4, we cannot shatter.\n",
    "\n",
    "When s=1, if [a,b] = [$x_1$, $x_3$], for $x_1$, $x_3$, it will have value '1', but '−1' at $x_2$ . A single interval can only cover one continuous block of points, so it can’t include both $x_1$ ​and $x_3$ ​without also including $x_2$.\n",
    "\n",
    "When s=-1, if [a,b] = [$x_2$, $x_4$], for $x_2$, $x_4$, it will have value '-1', but '1' at $x_3 . A single interval can only cover one continuous block of points, so it can’t include both $x_2$ ​and $x_4$ ​without also including $x_3$.\n",
    "\n",
    "Therefore, VC dimension = 3.\n",
    "\n",
    "\n",
    "**b.**\n",
    "\n",
    "VC dimension = 3\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Part 2**\n",
    "\n",
    "Consider two hypothesis spaces $\\mathcal{H}_1$, $\\mathcal{H}_2$ such\n",
    "that $\\mathcal{H}_1 \\subset \\mathcal{H}_2$. Prove that the VC\n",
    "Dimension of $\\mathcal{H}_2$ is at least as large as the VC\n",
    "Dimension of $\\mathcal{H}_1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Programming Assignment** (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "In this assignment, you'll implement Naive Bayes and use this algorithm\n",
    "to classify the credit rating (good or bad) of a set of individuals. The\n",
    "textbook section relevant to this assignment is 24.2 on page 347.\n",
    "\n",
    "### Stencil Code & Data\n",
    "\n",
    "We have provided the following stencils:\n",
    "\n",
    "-   `Models` contains the `NaiveBayes` model which you will be\n",
    "    implementing.\n",
    "\n",
    "-   `Check Model` contains a series of tests to ensure you are coding your \n",
    "    model properly.\n",
    "\n",
    "-   `Main` is the entry point of your program which will read in the\n",
    "    data, run the classifiers and print the results. Note that\n",
    "    pre-processing has been done for you; feel free to examine the code\n",
    "    for what exactly was done.\n",
    "\n",
    "You should *not* modify any code in the `Main`. All the functions you\n",
    "need to fill in reside in `Models`, marked by `TODO`s. You can see a\n",
    "full description of them in the section below. \n",
    "\n",
    "### German Credit Dataset\n",
    "\n",
    "You will be using the commonly-used German Credit dataset, which\n",
    "includes 1000 total examples. The prediction task is to decide whether\n",
    "someone's credit is good (1) or bad (0). A full list of attributes can\n",
    "be found\n",
    "[**here**](https://archive.ics.uci.edu/ml/datasets/Statlog+%28German+Credit+Data%29);\n",
    "note that this includes sensitive attributes like sex, age, and personal\n",
    "status. The specific file we are using comes from [**Friedler et.al.,\n",
    "2019**](https://github.com/algofairness/fairness-comparison). This data\n",
    "is in the file `german_numerical-binsensitive.csv`.\n",
    "\n",
    "### Data Format\n",
    "\n",
    "The original feature values in this dataset are mixed---some\n",
    "categorical, some numerical. We have written all the preprocessing code\n",
    "for you, transforming numerical attributes into categories and encoding\n",
    "all attributes as binary features. After preprocessing, there are a\n",
    "total of 69 attributes which take on either 1 or 0. **`credit = 1`\n",
    "corresponds to \"good\\\" credit, and `credit = 0` corresponds to \"bad\\\"\n",
    "credit.**\n",
    "\n",
    "## **The Assignment**\n",
    "\n",
    "In `Models`, there are three functions you will implement. They are:\n",
    "\n",
    "-   `NaiveBayes`:\n",
    "\n",
    "    -   **train()** uses maximum likelihood estimation to learn the\n",
    "        parameters (attribute distributions and priors distribution).\n",
    "        Because all the features are binary values, you should use the\n",
    "        Bernoulli distribution (as described in lecture) for the\n",
    "        features. Remember to add Laplace smoothing as you calculate the\n",
    "        distributions.\n",
    "\n",
    "    -   **predict()** predicts the labels using the inputs of test data.\n",
    "        You should return 1-D numpy array.\n",
    "\n",
    "    -   **accuracy()** computes the percentage of the correctly\n",
    "        predicted labels over a dataset.\n",
    "\n",
    "Note that there is also a **print_fairness()** method implemented for\n",
    "you in `NaiveBayes`. You should not change this method. Additionally,\n",
    "you are not allowed to use any off-the-shelf packages that have already\n",
    "implemented Naive Bayes, such as scikit-learn; we're asking you to\n",
    "implement it yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[42m[ OK ]\u001b[0m Python version is 3.12.11\n",
      "\n",
      "\u001b[42m[ OK ]\u001b[0m matplotlib version 3.10.5 is installed.\n",
      "\u001b[42m[ OK ]\u001b[0m numpy version 2.3.2 is installed.\n",
      "\u001b[42m[ OK ]\u001b[0m sklearn version 1.7.1 is installed.\n",
      "\u001b[42m[ OK ]\u001b[0m pandas version 2.3.2 is installed.\n",
      "\u001b[42m[ OK ]\u001b[0m pytest version 8.4.1 is installed.\n",
      "\u001b[42m[ OK ]\u001b[0m torch version 2.7.1 is installed.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from packaging.version import parse as Version\n",
    "from platform import python_version\n",
    "\n",
    "OK = '\\x1b[42m[ OK ]\\x1b[0m'\n",
    "FAIL = \"\\x1b[41m[FAIL]\\x1b[0m\"\n",
    "\n",
    "try:\n",
    "    import importlib\n",
    "except ImportError:\n",
    "    print(FAIL, \"Python version 3.12.11 is required,\"\n",
    "                \" but %s is installed.\" % sys.version)\n",
    "\n",
    "def import_version(pkg, min_ver, fail_msg=\"\"):\n",
    "    mod = None\n",
    "    try:\n",
    "        mod = importlib.import_module(pkg)\n",
    "        if pkg in {'PIL'}:\n",
    "            ver = mod.VERSION\n",
    "        else:\n",
    "            ver = mod.__version__\n",
    "        if Version(ver) == Version(min_ver):\n",
    "            print(OK, \"%s version %s is installed.\"\n",
    "                  % (lib, min_ver))\n",
    "        else:\n",
    "            print(FAIL, \"%s version %s is required, but %s installed.\"\n",
    "                  % (lib, min_ver, ver))    \n",
    "    except ImportError:\n",
    "        print(FAIL, '%s not installed. %s' % (pkg, fail_msg))\n",
    "    return mod\n",
    "\n",
    "\n",
    "# first check the python version\n",
    "pyversion = Version(python_version())\n",
    "\n",
    "if pyversion >= Version(\"3.12.11\"):\n",
    "    print(OK, \"Python version is %s\" % pyversion)\n",
    "elif pyversion < Version(\"3.12.11\"):\n",
    "    print(FAIL, \"Python version 3.12.11 is required,\"\n",
    "                \" but %s is installed.\" % pyversion)\n",
    "else:\n",
    "    print(FAIL, \"Unknown Python version: %s\" % pyversion)\n",
    "\n",
    "    \n",
    "print()\n",
    "requirements = {'matplotlib': \"3.10.5\", 'numpy': \"2.3.2\",'sklearn': \"1.7.1\", \n",
    "                'pandas': \"2.3.2\", 'pytest': \"8.4.1\", 'torch':\"2.7.1\"}\n",
    "\n",
    "# now the dependencies\n",
    "for lib, required_version in list(requirements.items()):\n",
    "    import_version(lib, required_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class NaiveBayes(object):\n",
    "    \"\"\" Bernoulli Naive Bayes model\n",
    "    \n",
    "    @attrs:\n",
    "        n_classes:    the number of classes\n",
    "        attr_dist:    a 2D (n_classes x n_attributes) NumPy array of the attribute distributions\n",
    "        label_priors: a 1D NumPy array of the priors distribution\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_classes):\n",
    "        \"\"\" Initializes a NaiveBayes model with n_classes. \"\"\"\n",
    "        self.n_classes = n_classes\n",
    "        self.attr_dist = None\n",
    "        self.label_priors = None\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        \"\"\" Trains the model, using maximum likelihood estimation.\n",
    "        @params:\n",
    "            X_train: a 2D (n_examples x n_attributes) numpy array\n",
    "            y_train: a 1D (n_examples) numpy array\n",
    "        @return:\n",
    "            a tuple consisting of:\n",
    "                1) a 2D numpy array of the attribute distributions\n",
    "                2) a 1D numpy array of the priors distribution\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO\n",
    "        # n_examples = number of samples (rows)\n",
    "        # n_attributes = number of binary features (columns)\n",
    "        n_examples, n_attributes = X_train.shape\n",
    "        K = self.n_classes # K = number of possible classes\n",
    "        alpha = 1.0 # Laplace smoothing factor.\n",
    "\n",
    "        # Count how many samples belong to each class.\n",
    "        counts_per_class = np.array([(y_train == c).sum() for c in range(K)], dtype=float)\n",
    "        # Compute the prior probability for each class:\n",
    "        # P(Y=c) = (N_c + α) / (N + α*K)\n",
    "        label_priors = (counts_per_class + alpha) / (n_examples + alpha * K) \n",
    "        # Initialize a 2D array to hold conditional probabilities for each feature:\n",
    "        # attr_dist[c, j] = P(X_j = 1 | Y = c)\n",
    "        attr_dist = np.zeros((K, n_attributes), dtype=float)\n",
    "\n",
    "        # Loop over each class and estimate its feature probabilities\n",
    "        for c in range(K):\n",
    "            # Create a boolean mask selecting all samples that belong to class c\n",
    "            idx = (y_train == c)\n",
    "            Nc = int(idx.sum()) # number of sample of this class\n",
    "            if Nc > 0:\n",
    "                # Sum across rows (samples) within this class to count how often each feature = 1\n",
    "                sum_ones = X_train[idx].sum(axis=0)\n",
    "            else:\n",
    "                # If there are no samples of this class in the training set, just use a vector of zeros\n",
    "                sum_ones = np.zeros(n_attributes, dtype=float)\n",
    "            # Compute Bernoulli conditional probabilities with Laplace smoothing:\n",
    "            # P(X_j=1 | Y=c) = (sum_ones_j + α) / (N_c + 2α)\n",
    "            attr_dist[c, :] = (sum_ones + alpha) / (Nc + 2.0 * alpha)\n",
    "\n",
    "\n",
    "        self.attr_dist = attr_dist\n",
    "        self.label_priors = label_priors\n",
    "        return self.attr_dist, self.label_priors\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        \"\"\" Outputs a predicted label for each input in inputs.\n",
    "            Remember to convert to log space to avoid overflow/underflow\n",
    "            errors!\n",
    "\n",
    "        @params:\n",
    "            inputs: a 2D NumPy array containing inputs\n",
    "        @return:\n",
    "            a 1D numpy array of predictions\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO\n",
    "        X = np.asarray(inputs)\n",
    "        # Take the log of learned parameters.\n",
    "        log_theta = np.log(self.attr_dist) # log P(X_j=1 | Y=c)\n",
    "        log_one_minus = np.log(1.0 - self.attr_dist) # log P(X_j=0 | Y=c)\n",
    "        log_priors = np.log(self.label_priors) # log P(Y=c)\n",
    "\n",
    "        n_samples, d = X.shape # number of samples and features\n",
    "        K = self.attr_dist.shape[0] # number of classes\n",
    "        scores = np.empty((n_samples, K), dtype=float)\n",
    "        # For each class, compute the total log-probability of every sample\n",
    "        for c in range(K):\n",
    "            scores[:, c] = (\n",
    "                log_priors[c]\n",
    "                + X @ log_theta[c, :].T\n",
    "                + (1.0 - X) @ log_one_minus[c, :].T\n",
    "            )\n",
    "        preds = np.argmax(scores, axis=1).astype(int)\n",
    "        return preds\n",
    "\n",
    "    def accuracy(self, X_test, y_test):\n",
    "        \"\"\" Outputs the accuracy of the trained model on a given dataset (data).\n",
    "\n",
    "        @params:\n",
    "            X_test: a 2D numpy array of examples\n",
    "            y_test: a 1D numpy array of labels\n",
    "        @return:\n",
    "            a float number indicating accuracy (between 0 and 1)\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO\n",
    "        y_test = np.asarray(y_test).astype(int)\n",
    "        preds = self.predict(X_test)\n",
    "        return np.mean(preds == y_test)\n",
    "\n",
    "    def print_fairness(self, X_test, y_test, x_sens):\n",
    "        \"\"\" \n",
    "        ***DO NOT CHANGE what we have implemented here.***\n",
    "        \n",
    "        Prints measures of the trained model's fairness on a given dataset (data).\n",
    "\n",
    "        For all of these measures, x_sens == 1 corresponds to the \"privileged\"\n",
    "        class, and x_sens == 0 corresponds to the \"disadvantaged\" class. Remember that\n",
    "        y == 1 corresponds to \"good\" credit. \n",
    "\n",
    "        @params:\n",
    "            X_test: a 2D numpy array of examples\n",
    "            y_test: a 1D numpy array of labels\n",
    "            x_sens: a numpy array of sensitive attribute values\n",
    "        @return:\n",
    "\n",
    "        \"\"\"\n",
    "        predictions = self.predict(X_test)\n",
    "\n",
    "        # Disparate Impact (80% rule): A measure based on base rates: one of\n",
    "        # two tests used in legal literature. All unprivileged classes are\n",
    "        # grouped together as values of 0 and all privileged classes are given\n",
    "        # the class 1. . Given data set D = (S,X,Y), with protected\n",
    "        # attribute S (e.g., race, sex, religion, etc.), remaining attributes X,\n",
    "        # and binary class to be predicted Y (e.g., “will hire”), we will say\n",
    "        # that D has disparate impact if:\n",
    "        # P[Y^ = 1 | S != 1] / P[Y^ = 1 | S = 1] <= (t = 0.8). \n",
    "        # Note that this 80% rule is based on US legal precedent; mathematically,\n",
    "        # perfect \"equality\" would mean\n",
    "\n",
    "        di = np.mean(predictions[np.where(x_sens==0)])/np.mean(predictions[np.where(x_sens==1)])\n",
    "        print(\"Disparate impact: \" + str(di))\n",
    "\n",
    "        # Group-conditioned error rates! False positives/negatives conditioned on group\n",
    "        \n",
    "        pred_priv = predictions[np.where(x_sens==1)]\n",
    "        pred_unpr = predictions[np.where(x_sens==0)]\n",
    "        y_priv = y_test[np.where(x_sens==1)]\n",
    "        y_unpr = y_test[np.where(x_sens==0)]\n",
    "\n",
    "        # s-TPR (true positive rate) = P[Y^=1|Y=1,S=s]\n",
    "        priv_tpr = np.sum(np.logical_and(pred_priv == 1, y_priv == 1))/np.sum(y_priv)\n",
    "        unpr_tpr = np.sum(np.logical_and(pred_unpr == 1, y_unpr == 1))/np.sum(y_unpr)\n",
    "\n",
    "        # s-TNR (true negative rate) = P[Y^=0|Y=0,S=s]\n",
    "        priv_tnr = np.sum(np.logical_and(pred_priv == 0, y_priv == 0))/(len(y_priv) - np.sum(y_priv))\n",
    "        unpr_tnr = np.sum(np.logical_and(pred_unpr == 0, y_unpr == 0))/(len(y_unpr) - np.sum(y_unpr))\n",
    "\n",
    "        # s-FPR (false positive rate) = P[Y^=1|Y=0,S=s]\n",
    "        priv_fpr = 1 - priv_tnr \n",
    "        unpr_fpr = 1 - unpr_tnr \n",
    "\n",
    "        # s-FNR (false negative rate) = P[Y^=0|Y=1,S=s]\n",
    "        priv_fnr = 1 - priv_tpr \n",
    "        unpr_fnr = 1 - unpr_tpr\n",
    "\n",
    "        print(\"FPR (priv, unpriv): \" + str(priv_fpr) + \", \" + str(unpr_fpr))\n",
    "        print(\"FNR (priv, unpriv): \" + str(priv_fnr) + \", \" + str(unpr_fnr))\n",
    "    \n",
    "    \n",
    "        # #### ADDITIONAL MEASURES IF YOU'RE CURIOUS #####\n",
    "\n",
    "        # Calders and Verwer (CV) : Similar comparison as disparate impact, but\n",
    "        # considers difference instead of ratio. Historically, this measure is\n",
    "        # used in the UK to evalutate for gender discrimination. Uses a similar\n",
    "        # binary grouping strategy. Requiring CV = 1 is also called demographic\n",
    "        # parity.\n",
    "\n",
    "        cv = 1 - (np.mean(predictions[np.where(x_sens==1)]) - np.mean(predictions[np.where(x_sens==0)]))\n",
    "\n",
    "        # Group Conditioned Accuracy: s-Accuracy = P[Y^=y|Y=y,S=s]\n",
    "\n",
    "        priv_accuracy = np.mean(predictions[np.where(x_sens==1)] == y_test[np.where(x_sens==1)])\n",
    "        unpriv_accuracy = np.mean(predictions[np.where(x_sens==0)] == y_test[np.where(x_sens==0)])\n",
    "\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Check Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT EDIT!\n",
    "\n",
    "import pytest\n",
    "# Sets random seed for testing purposes\n",
    "np.random.seed(0)\n",
    "\n",
    "# Creates Test Models with 2 & 3 classes\n",
    "test_model1 = NaiveBayes(2)\n",
    "test_model2 = NaiveBayes(2)\n",
    "test_model3 = NaiveBayes(3)\n",
    "\n",
    "# Creates Test Data\n",
    "x1 = np.array([[0,0,1], [0,1,0], [1,0,1], [1,1,1], [0,0,1]])\n",
    "y1 = np.array([0,0,1,1,0])\n",
    "x_test1 = np.array([[1,0,0],[0,0,0],[1,1,1],[0,1,0], [1,1,0]])\n",
    "y_test1 = np.array([0,0,1,0,1])\n",
    "\n",
    "x2 = np.array([[0,0,1], [0,1,1], [1,1,1], [1,1,1], [0,0,0], [1,1,0]])\n",
    "y2 = np.array([0,1,1,1,0,1])\n",
    "x_test2 = np.array([[0,0,1], [0,1,1], [1,1,1], [1,0,0]])\n",
    "y_test2 = np.array([0,1,1,0])\n",
    "\n",
    "x3 = np.array([[0,0,0,0], [0,0,0,1], [0,0,1,0], [0,0,1,1], [0,1,0,0], [0,1,0,1],\n",
    "               [0,1,1,0], [0,1,1,1], [1,0,0,0], [1,0,0,1], [1,0,1,0], [1,0,1,1]])\n",
    "y3 = np.array([0, 0, 1, 1, 1, 0, 2, 0, 0, 2, 1, 1])\n",
    "\n",
    "x_test3 = np.array([[1, 1, 0, 0], [1, 1, 0, 1], [1, 1, 1, 0], [1, 1, 1, 1]])\n",
    "y_test3 = np.array([1, 1, 0, 0])\n",
    "\n",
    "# Test Models\n",
    "def check_train_dtype(model, attrs, priors, x_train, y_train):\n",
    "    assert isinstance(attrs, np.ndarray)\n",
    "    assert attrs.ndim==2 and attrs.shape==(model.n_classes, x_train.shape[1])\n",
    "    assert isinstance(priors, np.ndarray)\n",
    "    assert priors.ndim==1 and priors.shape==(model.n_classes, )\n",
    "    \n",
    "\n",
    "attrs1, priors1 = test_model1.train(x1,y1)\n",
    "check_train_dtype(test_model1, attrs1, priors1, x1, y1)\n",
    "assert (attrs1 == pytest.approx(np.array([[.2, .4, .6],[.75, .5, .75]]),0.01))\n",
    "assert (priors1 == pytest.approx(np.array([0.571, 0.429]), 0.01))\n",
    "\n",
    "attrs2, priors2 = test_model2.train(x2, y2)\n",
    "check_train_dtype(test_model2, attrs2, priors2, x2, y2)\n",
    "assert (attrs2 ==  pytest.approx(np.array([[.25, .25, .5],[.67, .83, .67]]), 0.01))\n",
    "assert (priors2 == pytest.approx(np.array([0.375, 0.625]), 0.01))\n",
    "\n",
    "attrs3, priors3 = test_model3.train(x3, y3)\n",
    "check_train_dtype(test_model3, attrs3, priors3, x3, y3)\n",
    "assert (attrs3 == pytest.approx(np.array([[0.28571,0.428571,0.28571,0.57142],[0.42857,0.28571,0.71428,0.428571],[0.5,0.5,0.5,0.5]]),0.01))\n",
    "assert (priors3 == pytest.approx(np.array([0.4, 0.4, 0.2]), 0.01))\n",
    "\n",
    "# Test Model Predictions\n",
    "def check_test_dtype(pred, x_test):\n",
    "    assert isinstance(pred,np.ndarray)\n",
    "    assert pred.ndim==1 and pred.shape==(x_test.shape[0], )\n",
    "\n",
    "pred1 = test_model1.predict(x_test1)\n",
    "check_test_dtype(pred1, x_test1)\n",
    "assert (pred1 == np.array([1, 0, 1, 0, 1])).all()\n",
    "\n",
    "pred2 = test_model2.predict(x_test2)\n",
    "check_test_dtype(pred2, x_test2)\n",
    "assert (pred2 == np.array([0, 1, 1, 0])).all()\n",
    "\n",
    "pred3 = test_model3.predict(x_test3)\n",
    "check_test_dtype(pred3, x_test3)\n",
    "assert (pred3 == np.array([0, 0, 1, 1])).all()\n",
    "\n",
    "# Test Model Accuracy\n",
    "assert test_model1.accuracy(x_test1, y_test1) == .8\n",
    "assert test_model2.accuracy(x_test2, y_test2) == 1.0\n",
    "assert test_model3.accuracy(x_test3, y_test3) == 0.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Main**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Train accuracy:\n",
      "0.7742857142857142\n",
      "------------------------------------------------------------\n",
      "Test accuracy:\n",
      "0.7257142857142858\n",
      "------------------------------------------------------------\n",
      "Fairness measures:\n",
      "Disparate impact: 0.8294586797895808\n",
      "FPR (priv, unpriv): 0.7083333333333333, 0.37037037037037035\n",
      "FNR (priv, unpriv): 0.17500000000000004, 0.15909090909090906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0,\n",
       "       1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_credit():\n",
    "    \"\"\"\n",
    "    Gets and preprocesses German Credit data\n",
    "    \"\"\"\n",
    "    data = pd.read_csv('./data/german_numerical-binsensitive.csv') # Reads file - may change\n",
    "\n",
    "    # MONTH categorizing\n",
    "    data['month'] = pd.cut(data['month'],3, labels=['month_1', 'month_2', 'month_3'], retbins=True)[0]\n",
    "    # month bins: [ 3.932     , 26.66666667, 49.33333333, 72.        ]\n",
    "    a = pd.get_dummies(data['month'])\n",
    "    data = pd.concat([data, a], axis = 1)\n",
    "    data = data.drop(['month'], axis=1)\n",
    "\n",
    "    # CREDIT categorizing\n",
    "    data['credit_amount'] = pd.cut(data['credit_amount'], 3, labels=['cred_amt_1', 'cred_amt_2', 'cred_amt_3'], retbins=True)[0]\n",
    "    # credit bins: [  231.826,  6308.   , 12366.   , 18424.   ]\n",
    "    a = pd.get_dummies(data['credit_amount'])\n",
    "    data = pd.concat([data, a], axis = 1)\n",
    "    data = data.drop(['credit_amount'], axis=1)\n",
    "\n",
    "    for header in ['investment_as_income_percentage', 'residence_since', 'number_of_credits']:\n",
    "        a = pd.get_dummies(data[header], prefix=header)\n",
    "        data = pd.concat([data, a], axis = 1)\n",
    "        data = data.drop([header], axis=1)\n",
    "\n",
    "    # change from 1-2 classes to 0-1 classes\n",
    "    data['people_liable_for'] = data['people_liable_for'] -1\n",
    "    data['credit'] = -1*(data['credit']) + 2 # original encoding 1: good, 2: bad. we switch to 1: good, 0: bad\n",
    "\n",
    "    # balance dataset\n",
    "    data = data.reindex(np.random.permutation(data.index)) # shuffle\n",
    "    pos = data.loc[data['credit'] == 1]\n",
    "    neg = data.loc[data['credit'] == 0][:350]\n",
    "    combined = pd.concat([pos, neg])\n",
    "\n",
    "    y = data.iloc[:, data.columns == 'credit'].to_numpy()\n",
    "    x = data.drop(['credit', 'sex', 'age', 'sex-age'], axis=1).to_numpy()\n",
    "\n",
    "    # split into train and validation\n",
    "    X_train, X_val, y_train, y_val = x[:350, :], x[351:526, :], y[:350, :].reshape([350,]), y[351:526, :].reshape([175,])\n",
    "\n",
    "    # keep info about sex and age of validation rows for fairness portion\n",
    "    x_sex = data.iloc[:, data.columns == 'sex'].to_numpy()[351:526].reshape([175,])\n",
    "    x_age = data.iloc[:, data.columns == 'age'].to_numpy()[351:526].reshape([175,])\n",
    "    x_sex_age = data.iloc[:, data.columns == 'sex-age'].to_numpy()[351:526].reshape([175,])\n",
    "\n",
    "    return X_train, X_val, y_train, y_val, x_sex, x_age, x_sex_age\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "X_train, X_val, y_train, y_val, x_sex, x_age, x_sex_age = get_credit()\n",
    "model = NaiveBayes(2)\n",
    "model.train(X_train, y_train)\n",
    "\n",
    "print(\"------------------------------------------------------------\")\n",
    "print(\"Train accuracy:\")\n",
    "print(model.accuracy(X_train, y_train))\n",
    "print(\"------------------------------------------------------------\")\n",
    "print(\"Test accuracy:\")\n",
    "print(model.accuracy(X_val, y_val))\n",
    "print(\"------------------------------------------------------------\")\n",
    "\n",
    "print(\"Fairness measures:\")\n",
    "model.print_fairness(X_val, y_val, x_sex_age)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Project Report** (10 points)\n",
    "\n",
    "### **Question 1**\n",
    "\n",
    "Report the training and testing accuracy of the Naive Bayes\n",
    "classifier. (A correct implementation should have testing accuracy\n",
    "above $70\\%$.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "From the program output, we can get training accuracy is 0.774 (77.4 %), testing accuracy is 0.726 (72.6 %). These results show that the Naive Bayes model fits the training data reasonably well with over 70 % accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 2**\n",
    "\n",
    "What strong assumption about the features/attributes of the data\n",
    "does Naive Bayes make? Comment on this assumption in the context of\n",
    "credit scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:** \n",
    "\n",
    "Naive Bayes makes the strong assumption that all features are conditionally independent given the class label. It assumes that once we know whether someone has good or bad credit, their features do not influence each other.\n",
    "\n",
    "In the context of credit scores, this assumption is unrealistic. Financial attributes are usually correlated — for example, people with higher income often request larger loans. However, Naive Bayes performs well in practice because it captures dominant patterns even when independence is violated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 3**\n",
    "\n",
    "This dataset was originally structured as follows:\n",
    "\n",
    "\n",
    "| Month | Credit Amount | Number of credits | ... | Credit |\n",
    "| ------| ------------- | ----------------- | --- | ------ |\n",
    "|   6   |      1169     |         2         | ... |    1   |\n",
    "|   48  |      5951     |         1         | ... |    2   |\n",
    "|   12  |      2096     |         1         | ... |    1   | \n",
    "|   9   |      2134     |         3         | ... |    1   |\n",
    "\n",
    "For each of the above attributes, describe what transformations to\n",
    "the original dataset would need to occur for it to be usable in a\n",
    "Bernoulli Naive Bayes model. *(hint: every attribute must take on\n",
    "the value of 0 or 1)* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "Bernoulli Naive Bayes requires every feature to be binary (0 or 1). Therefore, each original numeric or categorical column must be converted into one-hot or binned binary indicators.\n",
    "\n",
    "For number of credits and credit, we can use one-hot encoding to convert the value into value of 0 or 1. Because the possible values ​​are limited not widely spread, then one-hot encoding is sufficient. For example: if the variable 'credits' takes values {1, 2, 3}, we can create three new binary columns — credits_1, credits_2, and credits_3 — where only one of them equals 1 for each record, and other equal 0.\n",
    "\n",
    "For month and credit amount, we can divide each variable into different intervals, after separating, we use one-hot encoding. Because the possible values widely spread, if we use one-hot encoding directly, it might have too many columns and the model may not learn well. For example: if credit_amount ranges from 100 to 10,000, we can group it into three parts — low, medium, and high — and then create three binary columns: cred_amt_low, cred_amt_medium, and cred_amt_high. Each record will have exactly one of these equal to 1, and other equal 0.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 4**\n",
    "\n",
    "A different way to think about fairness is based on the errors the\n",
    "model makes. We define the false positive rate (FPR) as\n",
    "$P(\\hat Y = 1 | Y = 0)$, and the false negative rate (FNR) as\n",
    "$P(\\hat Y = 0 | Y = 1)$. Suppose we calculate FPR and FNR for each\n",
    "group. In words, what does the false positive rate and false\n",
    "negative rate represent in the context of credit ratings? What are\n",
    "the implications if one group's FPR is much higher than the other's?\n",
    "What are the implications if one group's FNR is much higher than the\n",
    "other's? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "\n",
    "False Positive Rate (FPR) means among people who actually have bad credit, how many are incorrectly predicted as good credit. A high FPR means the model gives loans to risky borrowers, which increases financial loss risk.\n",
    "\n",
    "False Negative Rate (FNR) means among people who actually have good credit, how many are incorrectly predicted as bad credit. A high FNR means many creditworthy individuals are unfairly denied loans.\n",
    "\n",
    "If one group has a much higher FPR, the bank takes greater financial risk on that group. If one group has a much higher FNR, that group faces systematic discrimination, being wrongly rejected more often. Fair credit models should strive for balanced FPR and FNR across demographic groups."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data2060env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
